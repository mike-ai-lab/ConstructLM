<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Desktop Call Simulation</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Phosphor Icons -->
    <script src="https://unpkg.com/@phosphor-icons/web"></script>
    <!-- Marked for Markdown parsing -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

        body {
            font-family: 'Inter', sans-serif;
            background-color: #0f172a; /* Slate 900 */
            color: white;
            overflow: hidden; /* Prevent scroll on desktop sim */
        }

        /* Animations */
        @keyframes pulse-ring {
            0% { transform: scale(0.8); opacity: 0.5; box-shadow: 0 0 0 0 rgba(99, 102, 241, 0.7); }
            70% { transform: scale(1.1); opacity: 1; box-shadow: 0 0 0 20px rgba(99, 102, 241, 0); }
            100% { transform: scale(0.8); opacity: 0.5; box-shadow: 0 0 0 0 rgba(99, 102, 241, 0); }
        }

        .animate-ring {
            animation: pulse-ring 2s infinite cubic-bezier(0.4, 0, 0.6, 1);
        }

        /* Dynamic Visualizer Classes */
        .visualizer-bar {
            width: 6px;
            background-color: #6366f1; /* Indigo 500 */
            border-radius: 9999px;
            transition: height 0.1s ease;
            height: 6px; 
            min-height: 6px;
        }

        /* Custom Scrollbar for contact list */
        .custom-scroll::-webkit-scrollbar {
            width: 6px;
        }
        .custom-scroll::-webkit-scrollbar-track {
            background: #1e293b;
        }
        .custom-scroll::-webkit-scrollbar-thumb {
            background: #475569;
            border-radius: 3px;
        }

        /* Glass effect */
        .glass-panel {
            background: rgba(30, 41, 59, 0.7);
            backdrop-filter: blur(12px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .typing-dot {
            animation: typing 1.4s infinite ease-in-out both;
        }
        .typing-dot:nth-child(1) { animation-delay: -0.32s; }
        .typing-dot:nth-child(2) { animation-delay: -0.16s; }
        
        @keyframes typing {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1); }
        }
    </style>
</head>
<body class="flex h-screen antialiased selection:bg-indigo-500 selection:text-white">

    <!-- Sidebar (Desktop App Style) -->
    <aside class="w-80 bg-slate-900 border-r border-slate-800 flex flex-col hidden md:flex">
        <!-- Header -->
        <div class="h-16 flex items-center px-6 border-b border-slate-800">
            <div class="flex items-center gap-2 text-indigo-400 font-bold text-xl">
                <i class="ph-fill ph-aperture text-2xl"></i>
                <span>Nexus AI</span>
            </div>
        </div>

        <!-- Search -->
        <div class="p-4">
            <div class="relative">
                <i class="ph ph-magnifying-glass absolute left-3 top-2.5 text-slate-500"></i>
                <input type="text" placeholder="Search conversations..." class="w-full bg-slate-800 text-sm text-slate-300 rounded-lg pl-10 pr-4 py-2 focus:outline-none focus:ring-2 focus:ring-indigo-500 placeholder-slate-500">
            </div>
        </div>

        <!-- Contact List -->
        <div class="flex-1 overflow-y-auto custom-scroll px-2">
            <div class="mb-2 px-4 py-2 text-xs font-semibold text-slate-500 uppercase tracking-wider">Recents</div>
            
            <!-- Active Contact -->
            <div class="group flex items-center gap-3 p-3 rounded-xl bg-slate-800 cursor-pointer transition-colors">
                <div class="relative">
                    <div class="w-10 h-10 rounded-full bg-gradient-to-tr from-indigo-500 to-purple-500 flex items-center justify-center text-white font-bold text-sm shadow-lg">
                        AI
                    </div>
                    <div class="absolute bottom-0 right-0 w-3 h-3 bg-green-500 border-2 border-slate-800 rounded-full"></div>
                </div>
                <div class="flex-1 min-w-0">
                    <div class="flex justify-between items-baseline">
                        <h3 class="text-sm font-medium text-white truncate">Omni Assistant</h3>
                        <span class="text-xs text-indigo-400">Now</span>
                    </div>
                    <p class="text-xs text-slate-400 truncate">Ready to help you anytime.</p>
                </div>
            </div>

            <!-- Other Contacts -->
            <div class="group flex items-center gap-3 p-3 rounded-xl hover:bg-slate-800/50 cursor-pointer transition-colors mt-1">
                <div class="w-10 h-10 rounded-full bg-slate-700 flex items-center justify-center text-slate-300 font-bold text-sm">
                    RD
                </div>
                <div class="flex-1 min-w-0">
                    <div class="flex justify-between items-baseline">
                        <h3 class="text-sm font-medium text-slate-300 truncate">R&D Team</h3>
                        <span class="text-xs text-slate-600">2h</span>
                    </div>
                    <p class="text-xs text-slate-500 truncate">Meeting notes attached.</p>
                </div>
            </div>
        </div>

        <!-- User Profile -->
        <div class="p-4 border-t border-slate-800 bg-slate-900/50">
            <div class="flex items-center gap-3">
                <img src="https://api.dicebear.com/7.x/avataaars/svg?seed=Felix" alt="User" class="w-9 h-9 rounded-full bg-slate-700">
                <div class="flex-1">
                    <div class="text-sm font-medium text-white">Guest User</div>
                    <div class="text-xs text-slate-500">Online</div>
                </div>
                <button class="p-2 hover:bg-slate-800 rounded-lg text-slate-400 hover:text-white transition-colors">
                    <i class="ph ph-gear"></i>
                </button>
            </div>
        </div>
    </aside>

    <!-- Main Content Area -->
    <main class="flex-1 flex flex-col bg-slate-950 relative">
        
        <!-- Top Bar -->
        <header class="h-16 border-b border-slate-800 flex items-center justify-between px-6 bg-slate-900/50 backdrop-blur-md sticky top-0 z-10">
            <div class="flex items-center gap-4">
                <button class="md:hidden text-slate-400 hover:text-white">
                    <i class="ph ph-list text-2xl"></i>
                </button>
                <div class="flex items-center gap-3">
                    <h2 class="text-lg font-semibold text-white">Omni Assistant</h2>
                    <span class="px-2 py-0.5 rounded text-[10px] font-bold bg-indigo-500/20 text-indigo-400 border border-indigo-500/20">GEMINI FLASH ENABLED</span>
                </div>
            </div>
            <div class="flex items-center gap-4">
                <button class="p-2 text-slate-400 hover:text-white transition-colors">
                    <i class="ph ph-video-camera text-xl"></i>
                </button>
                <button class="p-2 text-slate-400 hover:text-white transition-colors">
                    <i class="ph ph-info text-xl"></i>
                </button>
            </div>
        </header>

        <!-- Chat Area (Background content) -->
        <div id="chatContainer" class="flex-1 p-6 overflow-y-auto flex flex-col gap-6 relative custom-scroll">
            <!-- Simulated Chat History -->
            <div class="flex justify-center my-4">
                <span class="text-xs text-slate-500 bg-slate-900 px-3 py-1 rounded-full border border-slate-800">Today, 9:41 AM</span>
            </div>

            <div class="flex gap-4 max-w-3xl mx-auto w-full">
                <div class="w-8 h-8 rounded-full bg-gradient-to-tr from-indigo-500 to-purple-500 flex-shrink-0 flex items-center justify-center text-xs font-bold text-white">AI</div>
                <div class="flex flex-col gap-1">
                    <div class="flex items-baseline gap-2">
                        <span class="text-sm font-semibold text-white">Omni Assistant</span>
                        <span class="text-xs text-slate-500">09:41 AM</span>
                    </div>
                    <div class="bg-slate-800 p-3 rounded-2xl rounded-tl-none text-slate-300 text-sm leading-relaxed border border-slate-700/50">
                        Hello! I'm ready to assist you. Click "Start Call" to have a ✨ real live conversation powered by Gemini.
                    </div>
                </div>
            </div>

            <!-- Messages will be injected here -->
            <div id="messagesEnd" class="h-4"></div>
        </div>

        <!-- Input Area -->
        <div class="p-6 pt-2">
            <div class="max-w-3xl mx-auto w-full">
                <div class="bg-slate-800/50 border border-slate-700 rounded-xl p-2 flex items-center gap-2">
                    <button class="p-2 text-slate-400 hover:text-white transition-colors">
                        <i class="ph ph-plus-circle text-xl"></i>
                    </button>
                    <input type="text" placeholder="Message Omni Assistant..." class="bg-transparent flex-1 text-white placeholder-slate-500 focus:outline-none text-sm px-2">
                    <button id="startCallBtn" class="bg-gradient-to-r from-indigo-600 to-purple-600 hover:from-indigo-700 hover:to-purple-700 text-white px-4 py-2 rounded-lg text-sm font-medium transition-colors flex items-center gap-2 shadow-lg shadow-indigo-500/20">
                        <i class="ph-fill ph-phone"></i>
                        <span>Start ✨ Call</span>
                    </button>
                </div>
                <div class="text-center mt-2">
                    <p class="text-[10px] text-slate-600">Powered by Gemini 2.5 Flash & Gemini TTS.</p>
                </div>
            </div>
        </div>

        <!-- ========================================== -->
        <!-- CALL OVERLAY -->
        <!-- ========================================== -->
        <div id="callOverlay" class="absolute inset-0 z-50 bg-slate-950/90 backdrop-blur-md flex items-center justify-center opacity-0 pointer-events-none transition-all duration-500">
            
            <!-- Glass Card Container -->
            <div class="glass-panel w-full max-w-sm rounded-3xl p-8 flex flex-col items-center shadow-2xl transform scale-95 transition-transform duration-500 relative overflow-hidden" id="callCard">
                
                <!-- Background decorative elements -->
                <div class="absolute top-0 left-0 w-full h-1 bg-gradient-to-r from-indigo-500 via-purple-500 to-pink-500"></div>

                <!-- State: Avatar Area -->
                <div class="relative mb-6 mt-4">
                    <!-- Ripple Animation -->
                    <div id="rippleRing" class="absolute inset-0 rounded-full bg-indigo-500/20 hidden"></div>
                    
                    <!-- Avatar Image -->
                    <div class="w-28 h-28 rounded-full bg-gradient-to-br from-slate-800 to-slate-900 border-4 border-slate-700 flex items-center justify-center relative z-10 overflow-hidden shadow-2xl">
                        <div class="bg-gradient-to-tr from-indigo-600 to-purple-600 w-full h-full flex items-center justify-center">
                            <i class="ph-fill ph-robot text-5xl text-white"></i>
                        </div>
                    </div>

                    <!-- Connection Status Indicator -->
                    <div id="statusDot" class="absolute bottom-2 right-2 w-6 h-6 bg-amber-500 border-4 border-slate-800 rounded-full z-20 transition-colors duration-300"></div>
                </div>

                <!-- Text Info -->
                <h3 class="text-2xl font-bold text-white mb-1">Omni Assistant</h3>
                <p id="callStatusText" class="text-indigo-300 text-sm font-medium mb-8 h-5">Connecting...</p>

                <!-- Audio Visualizer (Dynamic) -->
                <div id="audioVisualizer" class="h-12 flex items-center justify-center gap-1.5 mb-8 w-full px-8">
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                    <div class="visualizer-bar"></div>
                </div>

                <!-- Controls -->
                <div class="flex items-center gap-6">
                    <button id="micToggleBtn" class="p-4 rounded-full bg-slate-700/50 hover:bg-slate-700 text-white transition-all hover:scale-105 active:scale-95">
                        <i class="ph-fill ph-microphone text-xl"></i>
                    </button>
                    
                    <button onclick="endCall()" class="p-5 rounded-full bg-red-500 hover:bg-red-600 text-white shadow-lg shadow-red-500/30 transition-all hover:scale-105 active:scale-95">
                        <i class="ph-fill ph-phone-slash text-2xl"></i>
                    </button>
                    
                    <button class="p-4 rounded-full bg-slate-700/50 hover:bg-slate-700 text-white transition-all hover:scale-105 active:scale-95">
                        <i class="ph-fill ph-video-camera text-xl"></i>
                    </button>
                </div>
                
                <div class="mt-6 text-[10px] text-slate-500 font-mono">
                    GEMINI-2.5-FLASH • TTS
                </div>

            </div>
        </div>

    </main>

    <script>
        // --- Gemini API Configuration ---
        const apiKey = "AIzaSyBKvswkku5aScKDGTk5NiPWn1ewCZMhmRE";
        
        // --- DOM Elements ---
        const startBtn = document.getElementById('startCallBtn');
        const overlay = document.getElementById('callOverlay');
        const card = document.getElementById('callCard');
        const statusText = document.getElementById('callStatusText');
        const statusDot = document.getElementById('statusDot');
        const ripple = document.getElementById('rippleRing');
        const visualizerBars = document.querySelectorAll('.visualizer-bar');
        const chatContainer = document.getElementById('chatContainer');
        const messagesEnd = document.getElementById('messagesEnd');
        const micToggleBtn = document.getElementById('micToggleBtn');

        // --- State Variables ---
        let audioContext = null;
        let analyser = null;
        let isCallActive = false;
        let recognition = null;
        let isSpeaking = false;
        let currentAudioSource = null;
        let visualizerInterval = null;
        let isMicMuted = false;

        // --- Event Listeners ---
        startBtn.addEventListener('click', initiateCall);
        micToggleBtn.addEventListener('click', toggleMic);

        // --- Gemini Integration ---

        async function fetchGeminiText(userPrompt) {
            if (!apiKey) {
                console.warn("No API key found. Simulating response.");
                return "I'm sorry, I cannot connect to the brain right now. Please check the API configuration.";
            }

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{
                            parts: [{ text: "You are Omni, a helpful, friendly, and concise AI assistant having a voice conversation. Keep responses short (under 2 sentences) and conversational. User says: " + userPrompt }]
                        }]
                    })
                });
                
                if (!response.ok) throw new Error('Gemini Text API failed');
                const data = await response.json();
                return data.candidates[0].content.parts[0].text;
            } catch (error) {
                console.error("Text Gen Error:", error);
                return "I'm having trouble thinking right now.";
            }
        }

        async function fetchGeminiTTS(text) {
             if (!apiKey) return;

             try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: text }] }],
                        generationConfig: {
                            responseModalities: ["AUDIO"],
                            speechConfig: {
                                voiceConfig: {
                                    prebuiltVoiceConfig: { voiceName: "Aoede" } // Aoede is a good voice
                                }
                            }
                        }
                    })
                });

                if (!response.ok) throw new Error('Gemini TTS API failed');
                const data = await response.json();
                const base64Audio = data.candidates[0].content.parts[0].inlineData.data;
                return base64Audio;
             } catch (error) {
                 console.error("TTS Error:", error);
                 return null;
             }
        }

        // --- Audio & PCM Handling ---

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        async function playGeminiAudio(base64Data) {
            if (!audioContext) return;
            
            // Gemini TTS returns raw PCM 16-bit, 24kHz usually.
            // We need to convert this raw PCM into an AudioBuffer manually or use a WAV header.
            // Simplified approach: Decode logic for raw PCM16LE mono 24kHz
            
            const arrayBuffer = base64ToArrayBuffer(base64Data);
            const dataView = new DataView(arrayBuffer);
            const numSamples = arrayBuffer.byteLength / 2;
            const float32Data = new Float32Array(numSamples);
            
            // Convert PCM16 to Float32
            for (let i = 0; i < numSamples; i++) {
                const int16 = dataView.getInt16(i * 2, true); // Little endian
                float32Data[i] = int16 / 32768.0;
            }

            // Create AudioBuffer (Mono, 24kHz matches Gemini typically)
            const audioBuffer = audioContext.createBuffer(1, numSamples, 24000);
            audioBuffer.getChannelData(0).set(float32Data);

            // Play
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            
            // Analyzer for visualizer
            const analyserNode = audioContext.createAnalyser();
            analyserNode.fftSize = 32;
            source.connect(analyserNode);
            analyserNode.connect(audioContext.destination);
            
            currentAudioSource = source;
            analyser = analyserNode;
            
            return new Promise((resolve) => {
                source.onended = () => {
                    isSpeaking = false;
                    resolve();
                };
                isSpeaking = true;
                startVisualizer(analyserNode);
                source.start(0);
            });
        }

        // --- Core Application Logic ---

        function initiateCall() {
            if (isCallActive) return;
            isCallActive = true;

            // Initialize Audio
            if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
            if (audioContext.state === 'suspended') audioContext.resume();

            // Setup Speech Recognition
            setupSpeechRecognition();

            // UI Transition
            overlay.classList.remove('opacity-0', 'pointer-events-none');
            card.classList.remove('scale-95');
            card.classList.add('scale-100');

            // Ringing State
            updateStatus("Calling...", "amber");
            ripple.classList.remove('hidden');
            ripple.classList.add('animate-ring');
            
            // Simulated Ringing Sound
            playRingtone();

            setTimeout(() => {
                connectCall();
            }, 2500);
        }

        function connectCall() {
            if (!isCallActive) return;
            
            stopRingtone();
            playConnectSound();
            
            ripple.classList.remove('animate-ring');
            ripple.classList.add('hidden');
            
            updateStatus("Listening...", "green");
            
            // Start listening for user voice
            startListening();
        }

        function setupSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false; // Capture one sentence at a time
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    if(!isSpeaking) updateStatus("Listening...", "green");
                };

                recognition.onresult = async (event) => {
                    const transcript = event.results[0][0].transcript;
                    if (transcript.trim() === "") return;

                    // Log user message
                    addMessageToChat('user', transcript);
                    
                    // Stop listening while AI thinks/speaks
                    updateStatus("Thinking...", "purple");
                    
                    // 1. Get Text Response
                    const aiText = await fetchGeminiText(transcript);
                    addMessageToChat('ai', aiText);

                    // 2. Get Audio
                    updateStatus("Speaking...", "indigo");
                    const audioBase64 = await fetchGeminiTTS(aiText);
                    
                    if (audioBase64) {
                        await playGeminiAudio(audioBase64);
                    }

                    // 3. Back to Listening
                    if (isCallActive) {
                        updateStatus("Listening...", "green");
                        try { recognition.start(); } catch(e){}
                    }
                };

                recognition.onerror = (event) => {
                    console.log("Speech Error:", event.error);
                    if (isCallActive && event.error !== 'no-speech') {
                         // Restart silently if generic error, but 'no-speech' is handled by end event usually
                         // For simplicity, we just try to restart after a delay
                    }
                };
                
                recognition.onend = () => {
                    if (isCallActive && !isSpeaking) {
                        try { recognition.start(); } catch(e){}
                    }
                };

            } else {
                alert("Web Speech API not supported in this browser. Voice features unavailable.");
                endCall();
            }
        }

        function startListening() {
            try {
                if (recognition && !isSpeaking && !isMicMuted) recognition.start();
            } catch (e) { /* Already started */ }
        }

        function stopListening() {
            try {
                if (recognition) recognition.stop();
            } catch (e) { }
        }

        function endCall() {
            isCallActive = false;
            stopListening();
            stopRingtone();
            if (currentAudioSource) try { currentAudioSource.stop(); } catch(e){}
            
            playDisconnectSound();

            overlay.classList.add('opacity-0', 'pointer-events-none');
            card.classList.remove('scale-100');
            card.classList.add('scale-95');

            setTimeout(() => {
                updateStatus("Connecting...", "amber");
                stopVisualizer();
            }, 500);
        }

        function toggleMic() {
            isMicMuted = !isMicMuted;
            const icon = micToggleBtn.querySelector('i');
            
            if (isMicMuted) {
                stopListening();
                micToggleBtn.classList.replace('bg-slate-700/50', 'bg-red-500');
                micToggleBtn.classList.replace('hover:bg-slate-700', 'hover:bg-red-600');
                icon.classList.replace('ph-microphone', 'ph-microphone-slash');
                updateStatus("Mic Muted", "slate");
            } else {
                micToggleBtn.classList.replace('bg-red-500', 'bg-slate-700/50');
                micToggleBtn.classList.replace('hover:bg-red-600', 'hover:bg-slate-700');
                icon.classList.replace('ph-microphone-slash', 'ph-microphone');
                updateStatus("Listening...", "green");
                startListening();
            }
        }

        // --- UI Helpers ---

        function updateStatus(text, color) {
            statusText.innerText = text;
            
            let colorClass = "";
            switch(color) {
                case 'green': colorClass = "bg-green-500"; break;
                case 'amber': colorClass = "bg-amber-500"; break;
                case 'indigo': colorClass = "bg-indigo-500"; break;
                case 'purple': colorClass = "bg-purple-500"; break;
                case 'slate': colorClass = "bg-slate-500"; break;
                default: colorClass = "bg-green-500";
            }
            
            statusDot.className = `absolute bottom-2 right-2 w-6 h-6 border-4 border-slate-800 rounded-full z-20 transition-colors duration-300 ${colorClass}`;
        }

        function addMessageToChat(role, text) {
            const div = document.createElement('div');
            const isAI = role === 'ai';
            
            div.className = "flex gap-4 max-w-3xl mx-auto w-full animate-[pulse_0.5s_ease-in-out]";
            
            div.innerHTML = `
                <div class="w-8 h-8 rounded-full ${isAI ? 'bg-gradient-to-tr from-indigo-500 to-purple-500' : 'bg-slate-700'} flex-shrink-0 flex items-center justify-center text-xs font-bold text-white">
                    ${isAI ? 'AI' : '<i class="ph-fill ph-user"></i>'}
                </div>
                <div class="flex flex-col gap-1 w-full">
                    <div class="flex items-baseline gap-2">
                        <span class="text-sm font-semibold ${isAI ? 'text-white' : 'text-slate-300'}">${isAI ? 'Omni Assistant' : 'You'}</span>
                        <span class="text-xs text-slate-500">Just now</span>
                    </div>
                    <div class="${isAI ? 'bg-slate-800 border-slate-700/50' : 'bg-indigo-500/10 border-indigo-500/20'} p-3 rounded-2xl ${isAI ? 'rounded-tl-none' : 'rounded-tr-none'} text-slate-300 text-sm leading-relaxed border">
                        ${marked.parse(text)}
                    </div>
                </div>
            `;
            
            chatContainer.insertBefore(div, messagesEnd);
            messagesEnd.scrollIntoView({ behavior: 'smooth' });
        }

        // --- Visualizer Logic ---

        function startVisualizer(analyserNode) {
            if (visualizerInterval) clearInterval(visualizerInterval);
            
            const bufferLength = analyserNode.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            visualizerInterval = setInterval(() => {
                if (!isSpeaking) {
                    resetVisualizer();
                    return;
                }
                
                analyserNode.getByteFrequencyData(dataArray);
                
                // Map frequency data to 7 bars
                // We pick indices somewhat spread out to capture bass to treble
                const indices = [1, 3, 5, 8, 12, 18, 24];
                
                visualizerBars.forEach((bar, i) => {
                    const value = dataArray[indices[i] || 0];
                    const height = Math.max(6, (value / 255) * 48); // Max height 48px
                    bar.style.height = `${height}px`;
                });
            }, 50);
        }

        function stopVisualizer() {
            if (visualizerInterval) clearInterval(visualizerInterval);
            resetVisualizer();
        }

        function resetVisualizer() {
            visualizerBars.forEach(bar => {
                bar.style.height = '6px';
            });
        }

        // --- Ringtone Logic (Simulated) ---
        function playRingtone() {
            if (!audioContext) return;
            const osc = audioContext.createOscillator();
            const gainNode = audioContext.createGain();
            
            osc.connect(gainNode);
            gainNode.connect(audioContext.destination);
            
            osc.type = 'sine';
            osc.frequency.setValueAtTime(440, audioContext.currentTime);
            
            // Warble effect
            osc.frequency.setValueAtTime(400, audioContext.currentTime);
            osc.frequency.linearRampToValueAtTime(450, audioContext.currentTime + 0.05);

            gainNode.gain.setValueAtTime(0, audioContext.currentTime);
            gainNode.gain.linearRampToValueAtTime(0.1, audioContext.currentTime + 0.1);
            gainNode.gain.linearRampToValueAtTime(0.1, audioContext.currentTime + 1.5);
            gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + 1.6);
            
            gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + 3.0);
            gainNode.gain.linearRampToValueAtTime(0.1, audioContext.currentTime + 3.1);
            
            osc.start();
            window.currentOscillator = osc;
        }

        function stopRingtone() {
            if (window.currentOscillator) {
                try { window.currentOscillator.stop(); } catch(e){}
                window.currentOscillator = null;
            }
        }
        
        function playConnectSound() {
             if (!audioContext) return;
             // Simple success chime
             const osc = audioContext.createOscillator();
             const gain = audioContext.createGain();
             osc.connect(gain);
             gain.connect(audioContext.destination);
             osc.frequency.setValueAtTime(523.25, audioContext.currentTime);
             osc.frequency.exponentialRampToValueAtTime(659.25, audioContext.currentTime + 0.1);
             gain.gain.setValueAtTime(0.1, audioContext.currentTime);
             gain.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.5);
             osc.start();
             osc.stop(audioContext.currentTime + 0.5);
        }
        
        function playDisconnectSound() {
             if (!audioContext) return;
             const osc = audioContext.createOscillator();
             const gain = audioContext.createGain();
             osc.connect(gain);
             gain.connect(audioContext.destination);
             osc.frequency.setValueAtTime(400, audioContext.currentTime);
             osc.frequency.exponentialRampToValueAtTime(100, audioContext.currentTime + 0.2);
             gain.gain.setValueAtTime(0.1, audioContext.currentTime);
             gain.gain.linearRampToValueAtTime(0, audioContext.currentTime + 0.2);
             osc.start();
             osc.stop(audioContext.currentTime + 0.2);
        }

    </script>
</body>
</html>